{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab4d8a0",
   "metadata": {},
   "source": [
    "## Detect Overfitting and Underfitting with Learning Curves\n",
    "For this quiz, we'll be using three models to train the circular dataset below.\n",
    "\n",
    "- A Decision Tree model,\n",
    "- a Logistic Regression model, and\n",
    "- a Support Vector Machine model.\n",
    "\n",
    "![circle-data](circle-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6896715",
   "metadata": {},
   "source": [
    "One of the models overfits, one underfits, and the other one is just right. First, we'll write some code to draw the learning curves for each model, and finally we'll look at the learning curves to decide which model is which.\n",
    "\n",
    "First, let's remember that the way the curves look for the three models, is as follows:\n",
    "![learning-curves](learning-curves.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84827e36",
   "metadata": {},
   "source": [
    "For the first part of the quiz, all you need is to uncomment one of the classifiers, and hit 'Test Run' to see the graph of the Learning Curve. But if you like coding, here are some details. We'll be using the function called **learning_curve**:\n",
    "\n",
    "**train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator, X, y, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, num_trainings))**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c30cad",
   "metadata": {},
   "source": [
    "No need to worry about all the parameters of this function (you can read some more in here, but here we'll explain the main ones:\n",
    "\n",
    " - **estimator**, is the actual classifier we're using for the data, e.g., LogisticRegression() or GradientBoostingClassifier().\n",
    " - **X** and **y** is our data, split into features and labels.\n",
    " - **train_sizes** are the sizes of the chunks of data used to draw each point in the curve.\n",
    " - **train_scores** are the training scores for the algorithm trained on each chunk of data.\n",
    " - **test_scores** are the testing scores for the algorithm trained on each chunk of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8d2b5",
   "metadata": {},
   "source": [
    "Two very important observations:\n",
    "\n",
    "- The training and testing scores come in as a list of 3 values, and this is because the function uses 3-Fold Cross-Validation.\n",
    "- **Very important:** As you can see, we defined our curves with Training and Testing Error, and this function defines them with Training and Testing Score. **These are opposite, so the higher the error, the lower the score**. Thus, when you see the curve, you need to flip it upside down in your mind, in order to compare it with the curves above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805fb41",
   "metadata": {},
   "source": [
    "### Part 1: Drawing the learning curves\n",
    "In here, we'll be comparing three models:\n",
    "\n",
    "- A **Logistic Regression** model.\n",
    "- A **Decision Tree** model.\n",
    "- A **Support Vector Machine** model with an rbf kernel, and a gamma parameter of 1000 (this is another type of model, don't worry about how it works for now).\n",
    "\n",
    "Uncomment the code for each one, and examine the learning curve that gets drawn. If you're curious about the code used to draw the learning curves, it's on the **utils.py** tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0d20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import, read, and split data\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data.csv')\n",
    "import numpy as np\n",
    "X = np.array(data[['x1', 'x2']])\n",
    "y = np.array(data['y'])\n",
    "\n",
    "# Fix random seed\n",
    "np.random.seed(55)\n",
    "\n",
    "### Imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment one of the three classifiers, and hit \"Test Run\"\n",
    "# to see the learning curve. Use these to answer the quiz below.\n",
    "\n",
    "### higher the error, the lower the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0135c065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Logistic Regression\n",
    "estimator = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958037e",
   "metadata": {},
   "source": [
    "![logistic](logistic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb2d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree\n",
    "#estimator = GradientBoostingClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6b18e",
   "metadata": {},
   "source": [
    "\n",
    "![gradient](gradient.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Support Vector Machine\n",
    "#estimator = SVC(kernel='rbf', gamma=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3a315",
   "metadata": {},
   "source": [
    "![SVM](SVM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69933d",
   "metadata": {},
   "source": [
    "![quiz](quiz.png)\n",
    "\n",
    "We can observe from the curves that:\n",
    "\n",
    "- The **Logistic Regression** model has a low training and testing score.\n",
    "- The **Decision Tree** model has a high training and testing score.\n",
    "- The **Support Vector Machine** model has a high training score, and a low testing score.\n",
    "\n",
    "From here, we can determine that the Logistic Regression model underfits, the SVM model overfits, and the Decision Tree model is just right.\n",
    "\n",
    "Equivalently, we can flip this curves (as they measure score, and our original curves measure error), and compare them with the following three curves, we can see that they look a lot like the three curves we saw before. (Note: The fact that we flip the curves doesn't mean that the error is 1 minus the score. It only means that as the model gets better, the error decreases, and the score increases.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da90ef3",
   "metadata": {},
   "source": [
    "\n",
    "![error-curves](error-curves.png)\n",
    "\n",
    "Now, we should check if this is visible in the actual model. When we plot the boundary curves for each one of these models, we get the following:\n",
    "![models](models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74675999",
   "metadata": {},
   "source": [
    "When we look at the models above, does it make sense that the first one underfits, the second one is right, and the third one overfits? It does, right? We can see that the data is correctly bounded by a circle, or a square. What our models do, is the following:\n",
    "\n",
    "- The **Logistic Regression** model uses a line, which is too simplistic. It doesn't do very well on the training set. Thus, it underfits.\n",
    "- The **Decision Tree** model uses a square, which is a pretty good fit, and generalizes well. Thus, this model is good.\n",
    "- The **Support Vector Machine** model actually draws a tiny circle around each point. This is clearly just memorizing the training set, and won't generalize well. Thus, it overfits.\n",
    "\n",
    "It's always good to do a reality check when we can, and see that our models actually do have the behavior that the metrics tell us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0911aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
