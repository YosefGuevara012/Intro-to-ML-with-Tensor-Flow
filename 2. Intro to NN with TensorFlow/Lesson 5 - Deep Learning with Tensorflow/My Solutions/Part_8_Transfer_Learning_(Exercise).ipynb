{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2muxqaxvTlzk"
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "https://youtu.be/iIF9ZNw0ejs\n",
    "\n",
    "In this notebook, you'll learn how to use pre-trained networks to solve challenging problems in computer vision. Specifically, you'll use a network trained on [ImageNet](http://www.image-net.org/). ImageNet is a massive dataset with over 1 million labeled images in 1,000 categories.\n",
    "\n",
    "These pre-trained models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called **Transfer Learning**. Here we'll use transfer learning to train a network that can classify our cat and dog photos with near perfect accuracy.\n",
    "\n",
    "With [TensorFlow Hub](https://www.tensorflow.org/hub) you can download these pre-trained networks and use them in your applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QNYGxmtIXQP"
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmUJmdTpU1Pz"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_Abet3-Yydgw",
    "outputId": "266644f2-f473-4353-87a4-cf07385c1492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.6.0\n",
      "\t• tf.keras version: 2.6.0\n",
      "\t• Running on GPU\n"
     ]
    }
   ],
   "source": [
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMr2MeTCIhJd"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hrbFmp_2WJCc",
    "outputId": "80ce0d69-ce2d-4f4e-bff5-89b622e54110"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown split \"test\". Should be one of ['train'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9752/3508419270.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msplits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train[:60%]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train[60%:80%]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test[80%:]'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cats_vs_dogs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_supervised\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[0mas_dataset_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'read_config'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m   \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mas_dataset_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[1;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mas_supervised\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_supervised\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     )\n\u001b[1;32m--> 593\u001b[1;33m     \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_single_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[0mtypes_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m       mapped = [map_nested(function, v, dict_only, map_tuple)\n\u001b[0m\u001b[0;32m    178\u001b[0m                 for v in data_struct]\n\u001b[0;32m    179\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[0mtypes_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m       mapped = [map_nested(function, v, dict_only, map_tuple)\n\u001b[0m\u001b[0;32m    178\u001b[0m                 for v in data_struct]\n\u001b[0;32m    179\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[1;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m   \u001b[1;31m# Singleton\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[1;34m(self, split, shuffle_files, batch_size, decoders, read_config, as_supervised)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;31m# Build base dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m     ds = self._as_dataset(\n\u001b[0m\u001b[0;32m    612\u001b[0m         \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0mshuffle_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\u001b[0m in \u001b[0;36m_as_dataset\u001b[1;34m(self, split, decoders, read_config, shuffle_files)\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     )\n\u001b[1;32m--> 968\u001b[1;33m     return self._tfrecords_reader.read(\n\u001b[0m\u001b[0;32m    969\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[0minstructions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, name, instructions, split_infos, read_config, shuffle_files, decode_fn)\u001b[0m\n\u001b[0;32m    360\u001b[0m       )\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_read_instruction_to_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstructions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m   def read_files(\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36m_read_instruction_to_ds\u001b[1;34m(instruction)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \"\"\"\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_instruction_to_ds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m       file_instructions = make_file_instructions(\n\u001b[0m\u001b[0;32m    354\u001b[0m           name, split_infos, instruction, file_format=self._file_format)\n\u001b[0;32m    355\u001b[0m       return self.read_files(\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36mmake_file_instructions\u001b[1;34m(name, split_infos, instruction, file_format)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0minstruction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m   \u001b[1;31m# Create the absolute instruction (per split)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m   \u001b[0mabsolute_instructions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstruction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_absolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname2len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m   return _make_file_instructions_from_absolutes(\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36mto_absolute\u001b[1;34m(self, name2len)\u001b[0m\n\u001b[0;32m    665\u001b[0m       \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0m_AbsoluteInstruction\u001b[0m \u001b[0minstances\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m     \"\"\"\n\u001b[1;32m--> 667\u001b[1;33m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001b[0m\u001b[0;32m    668\u001b[0m             for rel_instr in self._relative_instructions]\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    665\u001b[0m       \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0m_AbsoluteInstruction\u001b[0m \u001b[0minstances\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m     \"\"\"\n\u001b[1;32m--> 667\u001b[1;33m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001b[0m\u001b[0;32m    668\u001b[0m             for rel_instr in self._relative_instructions]\n",
      "\u001b[1;32mD:\\Programas\\miniconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_datasets\\core\\tfrecords_reader.py\u001b[0m in \u001b[0;36m_rel_to_abs_instr\u001b[1;34m(rel_instr, name2len)\u001b[0m\n\u001b[0;32m    492\u001b[0m   \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrel_instr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname2len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m     raise ValueError('Unknown split \"{}\". Should be one of {}.'.format(\n\u001b[0m\u001b[0;32m    495\u001b[0m         split, list(name2len)))\n\u001b[0;32m    496\u001b[0m   \u001b[0mnum_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname2len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown split \"test\". Should be one of ['train']."
     ]
    }
   ],
   "source": [
    "\n",
    "splits = ['train[:60%]','train[60%:80%]', 'test[80%:]']\n",
    "\n",
    "dataset, dataset_info = tfds.load('cats_vs_dogs', split=splits, as_supervised=True, with_info=True)\n",
    "\n",
    "training_set, validation_set, test_set = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yotXUFkbI-9B"
   },
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "V7Vii2eIEBPl",
    "outputId": "9f70bea5-b3e1-4f7a-de91-1ff43f563a82"
   },
   "outputs": [],
   "source": [
    "dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "_LOJzPsiiz2Q",
    "outputId": "e58cf5d3-7b5f-4249-b016-cabcee549dfc"
   },
   "outputs": [],
   "source": [
    "num_classes = dataset_info.features['label'].num_classes\n",
    "total_num_examples = dataset_info.splits['train'].num_examples\n",
    "\n",
    "print('The Dataset has a total of:')\n",
    "print('\\u2022 {:,} classes'.format(num_classes))\n",
    "print('\\u2022 {:,} images'.format(total_num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KccTIDXNVUk3"
   },
   "source": [
    "As a technical note, if the total number of examples in your dataset is not a multiple of 100 (*i.e.* if `total_num_examples % 100 != 0`), then TensorFlow may not evenly distribute the data among subsplits. As we can see, our dataset has `23,262` examples, which is not a multiple of 100. Therefore, in this particular case, we should expect that our data would not be evenly distributed among the subsplits that we created. This means that even though we set our `split` to allocate 60\\% of the data to the training set, 20\\% of the data to the validation set, and 20\\% of the data to the test set, the actual number of images in each set may vary from these percentages. It is important to note, that these small differences will not affect our training process. We didn't have this issue before when we worked the MNIST and Fashion-MNIST datasets because both of these datasets had 70,000 examples. Since 70,000 is a multiple of 100, then the data was evenly distributed in both of those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lECJGR1hdaJH"
   },
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "IRoQodo3dXY2",
    "outputId": "6957ba36-81cf-47d0-b8a9-f1547bb22dc0"
   },
   "outputs": [],
   "source": [
    "for image, label in training_set.take(1):\n",
    "    image = image.numpy()\n",
    "    label = label.numpy()\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print('The label of this image is:', label)\n",
    "print('The class name of this image is:', class_names[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXdiexgZBnAq"
   },
   "source": [
    "## Create Pipeline\n",
    "\n",
    "The pre-trained model we are going to use requires that the input images have color values in the range `[0,1]` and a size of `(224, 224)`. We will therefore have to normalize the pixel values of our images and resize them to the appropriate size. We can normalize our pixel values in the usual way by dividing the original pixel values by `255` and to resize our images we can use the `tf.image.resize()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "kkGBYnL-BqH1",
    "outputId": "3d3fdbd5-7c7f-4ba1-e842-1a4877f5c20a"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = 224\n",
    "\n",
    "num_training_examples = (total_num_examples * train_split) // 100\n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (image_size, image_size))\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "\n",
    "training_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(batch_size).prefetch(1)\n",
    "validation_batches = validation_set.map(format_image).batch(batch_size).prefetch(1)\n",
    "testing_batches = test_set.map(format_image).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9OFVEQQSleKF"
   },
   "source": [
    "## Transfer Learning with TensorFlow Hub\n",
    "\n",
    "[TensorFlow Hub](https://www.tensorflow.org/hub) is an online repository of pre-trained models. In addition to complete pre-trained models, TensorFlow Hub also contains models without the last classification layer. These models can be used to perform transfer learning by adding a classification layer that suits the number of classes in your particular dataset. You can take a look at all the models available for TensorFlow 2.0 in [TensorFlow Hub](https://tfhub.dev/s?q=tf2-preview).\n",
    "\n",
    "In this notebook, we will use a network trained on the ImageNet dataset called MobileNet. MobileNet is a state-of-the-art convolutional neural network developed by Google. Convolutional neural networks are out of the scope of this course, but if you want to learn more about them, you can take a look at this [video](https://www.youtube.com/watch?v=2-Ol7ZB0MmU).\n",
    "\n",
    "In the cell below we download the pre-trained MobileNet model without the final classification layer from TensorFlow Hub using the `hub.KerasLayer(URL)` function. This function downloads the desired model form the given TensorFlow Hub `URL` and wraps it in a Keras layer so that we can integrate it in a `tf.keras` Sequential model later. Since this will be the first layer of our Sequential model, we need to specify the `input_shape` parameter. The shape of our input tensor must match the size of the images MobileNet was trained on, namely `(224,224,3)`. \n",
    "\n",
    "Our pre-trained model will be responsible for extracting the features of our images, we will therefore call this part of our model the `feature_extractor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59qI5xtTBjk7"
   },
   "outputs": [],
   "source": [
    "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "feature_extractor = hub.KerasLayer(URL, input_shape=(image_size, image_size,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTJTOxkfnlgd"
   },
   "source": [
    "It is important that we freeze the weights and biases in our pre-trained model so that we don't modify them during training. We can do this by setting the parameters of our model to non-trainable, as shown in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqtAGNlZnjvE"
   },
   "outputs": [],
   "source": [
    "feature_extractor.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VEEN4oUoZMW"
   },
   "source": [
    "## Build the Model\n",
    "\n",
    "We will now create a `tf.keras` Sequential model with our `feature_extractor` and a new classification layer. Since our dataset only has 2 classes (cat and dog) we create an output layer with only 2 units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "le6eV8RfoQHc",
    "outputId": "16eadcdf-35f9-450c-c121-cb52d872b778"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        feature_extractor,\n",
    "        tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSy0p05YpDmM"
   },
   "source": [
    "## Train the Model Using a GPU\n",
    "\n",
    "With our model built, we now need to train the new classification layer, but this time we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use a GPU to do the calculations. On a GPU, linear algebra computations are done in parallel, leading to 100x increased training speeds. TensorFlow will transparently run on a single GPU without requiring that we make changes to our code. With TensorFlow, it's also possible to train on multiple GPUs, further decreasing training time, but this requires that we make changes to our code to incorporate [distributed training](https://www.tensorflow.org/guide/distributed_training). \n",
    "\n",
    "We can use the `tf.test.is_gpu_available()` function to confirm that TensorFlow is using the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7BsmVnFCrT5u",
    "outputId": "8c25a339-afe6-487b-a6c0-203a05c7f651"
   },
   "outputs": [],
   "source": [
    "print('Is there a GPU Available:', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3BA5rWQuVaF"
   },
   "source": [
    "TensorFlow uses different string identifiers for CPUs and GPUs. For example, TensorFlow will use the identifier:\n",
    "\n",
    "```python\n",
    "'/CPU:0'\n",
    "```\n",
    "for the CPU of your machine; and it will use the identifier:\n",
    "\n",
    "```python\n",
    "'/GPU:0'\n",
    "```\n",
    "for the first GPU of your machine that is visible to TensorFlow. If your system has both devices, `/CPU:0` and `/GPU:0`, by default the GPU devices will be given priority when preforming TensorFlow operations (given that the TensorFlow operations have both CPU and GPU implementations). For example, the TensorFlow `tf.matmul` operation has both CPU and GPU kernels, therefore, the `/GPU:0` device will be selected to run `tf.matmul` unless you explicitly request running it on another device.\n",
    "\n",
    "### Manual Device Placement\n",
    "\n",
    "If you would like a particular TensorFlow operation to run on the device of your choice, instead of what's automatically selected for you by default, you can use:\n",
    "\n",
    "```python\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    perform operations\n",
    "```\n",
    "\n",
    "to have operations run on the CPU; and you can use:\n",
    "  \n",
    "```python\n",
    "# Place tensors on the GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    perform operations\n",
    "```\n",
    "\n",
    "to have operations run on the GPU.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Let's assume we have a system that has both devices, `/CPU:0` and `/GPU:0`. What will happen if we run the code below?\n",
    "\n",
    "```python\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.random.normal(...)\n",
    "    b = tf.random.normal(...)\n",
    "\n",
    "c = tf.matmul(a, b)\n",
    "```\n",
    "\n",
    "The above code will create both `a` and `b` using the CPU because we manually assigned those statements to the \n",
    "`/CPU:0` device using the `with tf.device('/CPU:0')` code block. However, since the statement `c = tf.matmul(a, b)` is NOT inside the `with tf.device('/CPU:0')` code block, then TensorFlow will run the `tf.matmul` operation on the `/GPU:0` device. TensorFlow will automatically copy tensors between devices if required.\n",
    "\n",
    "In the code below, we will multiply matrices of increasing size using both the CPU and GPU so you can see the difference in execution time. You will see, that as the size of the matrices increase, the execution time on the CPU increases rapidly, but on the GPU it stays constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_times(max_size = 650):\n",
    "    device_times = {'/GPU:0':[], '/CPU:0':[]}\n",
    "    matrix_sizes = range(450, max_size, 50)\n",
    "    len_matrix = len(matrix_sizes)\n",
    "\n",
    "    for i, size in enumerate(matrix_sizes):\n",
    "        for device_name in device_times.keys():\n",
    "            with tf.device(device_name):\n",
    "                m1 = tf.random.uniform(shape=(size,size), dtype=tf.float16)\n",
    "                m2 = tf.random.uniform(shape=(size,size), dtype=tf.float16)\n",
    "                start_time = time.time()\n",
    "                dot_operation = tf.matmul(m2, m1)\n",
    "                time_taken = time.time() - start_time\n",
    "                \n",
    "                if i > 0:\n",
    "                    device_times[device_name].append(time_taken)\n",
    "                    \n",
    "        percent_complete = (i + 1) / len_matrix\n",
    "        print('\\rPerforming Calculations. Please Wait... {:.0%} Complete'.format(percent_complete), end = '')\n",
    "    \n",
    "    matrix_sizes = matrix_sizes[1:]\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    plt.plot(matrix_sizes, device_times['/CPU:0'], 'o-', color='magenta', linewidth = 2, label = 'CPU')\n",
    "    plt.plot(matrix_sizes, device_times['/GPU:0'], 'o-', color='cyan', linewidth = 2, label='GPU')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('black')\n",
    "    plt.grid()\n",
    "    plt.ylabel('Time (s)', color='white', fontsize = 20)\n",
    "    plt.xlabel('Matrix size',  color='white', fontsize = 20)\n",
    "    plt.legend(prop={'size': 15})\n",
    "    plt.show()\n",
    "    \n",
    "plot_times(850)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUaXuhBorKXr"
   },
   "source": [
    "From here, I'll let you finish training the model. The process is the same as before except that now your model will automatically run on the GPU. You should get better than 95% accuracy easily.\n",
    "\n",
    ">**Exercise:** Train the `model` we created above to classify the cat and dog images in our dataset. Because we are using a pre-trained model, you will only need to train the model for a few epochs to get a high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "zsNPAHR9o7Gv",
    "outputId": "3de71c8e-56d0-495f-d386-ab400b14e4ba"
   },
   "outputs": [],
   "source": [
    "## Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBfxg0GoPdiO"
   },
   "source": [
    "# Check Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 858
    },
    "colab_type": "code",
    "id": "X_eKgwBe880Q",
    "outputId": "c48c3728-03ed-4c1c-df01-282196f75520"
   },
   "outputs": [],
   "source": [
    "for image_batch, label_batch in testing_batches.take(1):\n",
    "    ps = model.predict(image_batch)\n",
    "    images = image_batch.numpy().squeeze()\n",
    "    labels = label_batch.numpy()\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "for n in range(30):\n",
    "    plt.subplot(6,5,n+1)\n",
    "    plt.imshow(images[n], cmap = plt.cm.binary)\n",
    "    color = 'green' if np.argmax(ps[n]) == labels[n] else 'red'\n",
    "    plt.title(class_names[np.argmax(ps[n])], color=color)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41kBLcTJVX3y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part 8 - Transfer Learning (Solution).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
